{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1e532a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2c769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING DATA\n",
      "============================================================\n",
      "\n",
      "Train shape: (181507, 279)\n",
      "Test shape: (77789, 278)\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 1. LOAD DATA\n",
    "# ====================================\n",
    "print(\"=\" * 60)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(f\"\\nTrain shape: {df.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f49c8a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>product_type</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>indust_part</th>\n",
       "      <th>children_preschool</th>\n",
       "      <th>preschool_education_centers_raion</th>\n",
       "      <th>...</th>\n",
       "      <th>trc_sqm_5000_log</th>\n",
       "      <th>sport_count_5000_log</th>\n",
       "      <th>life_full_ratio</th>\n",
       "      <th>cafe_density_5000</th>\n",
       "      <th>high_floor</th>\n",
       "      <th>large_apartment</th>\n",
       "      <th>rooms_inferred</th>\n",
       "      <th>living_efficiency</th>\n",
       "      <th>price_doc</th>\n",
       "      <th>price_doc_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106299</td>\n",
       "      <td>-0.280658</td>\n",
       "      <td>50.127224</td>\n",
       "      <td>10.970619</td>\n",
       "      <td>Type_A</td>\n",
       "      <td>Area_380</td>\n",
       "      <td>0.099506</td>\n",
       "      <td>0.222095</td>\n",
       "      <td>6255.829172</td>\n",
       "      <td>4.076307</td>\n",
       "      <td>...</td>\n",
       "      <td>14.688605</td>\n",
       "      <td>4.046719</td>\n",
       "      <td>-178.606113</td>\n",
       "      <td>16.135148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>69.684824</td>\n",
       "      <td>6.452158</td>\n",
       "      <td>2.008504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125559</td>\n",
       "      <td>2129.178675</td>\n",
       "      <td>3438.561939</td>\n",
       "      <td>6.282464</td>\n",
       "      <td>Type_B</td>\n",
       "      <td>Area_1375</td>\n",
       "      <td>0.588042</td>\n",
       "      <td>0.157862</td>\n",
       "      <td>7391.899017</td>\n",
       "      <td>7.608949</td>\n",
       "      <td>...</td>\n",
       "      <td>15.293149</td>\n",
       "      <td>3.805732</td>\n",
       "      <td>1.614971</td>\n",
       "      <td>166.763131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>229.0</td>\n",
       "      <td>1.614213</td>\n",
       "      <td>101.661749</td>\n",
       "      <td>4.631440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204969</td>\n",
       "      <td>44.255548</td>\n",
       "      <td>-15.662341</td>\n",
       "      <td>0.894701</td>\n",
       "      <td>Type_A</td>\n",
       "      <td>Area_272</td>\n",
       "      <td>0.074837</td>\n",
       "      <td>0.266754</td>\n",
       "      <td>5658.091711</td>\n",
       "      <td>4.054293</td>\n",
       "      <td>...</td>\n",
       "      <td>14.162732</td>\n",
       "      <td>3.987516</td>\n",
       "      <td>-0.353907</td>\n",
       "      <td>12.076017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.346087</td>\n",
       "      <td>6.257546</td>\n",
       "      <td>1.982042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248026</td>\n",
       "      <td>2622.821354</td>\n",
       "      <td>1373.058212</td>\n",
       "      <td>15.971260</td>\n",
       "      <td>Type_B</td>\n",
       "      <td>Area_1750</td>\n",
       "      <td>0.850289</td>\n",
       "      <td>0.393528</td>\n",
       "      <td>13262.734984</td>\n",
       "      <td>6.832598</td>\n",
       "      <td>...</td>\n",
       "      <td>14.881627</td>\n",
       "      <td>4.765929</td>\n",
       "      <td>0.523504</td>\n",
       "      <td>184.953625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.523305</td>\n",
       "      <td>90.592523</td>\n",
       "      <td>4.517350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51881</td>\n",
       "      <td>52.877556</td>\n",
       "      <td>12.392606</td>\n",
       "      <td>2.876796</td>\n",
       "      <td>Type_A</td>\n",
       "      <td>Area_1773</td>\n",
       "      <td>0.070450</td>\n",
       "      <td>0.238344</td>\n",
       "      <td>3842.416286</td>\n",
       "      <td>5.030503</td>\n",
       "      <td>...</td>\n",
       "      <td>14.302936</td>\n",
       "      <td>4.114335</td>\n",
       "      <td>0.234364</td>\n",
       "      <td>14.630758</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230014</td>\n",
       "      <td>8.486698</td>\n",
       "      <td>2.249891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      full_sq      life_sq      floor product_type   sub_area  \\\n",
       "0  106299    -0.280658    50.127224  10.970619       Type_A   Area_380   \n",
       "1  125559  2129.178675  3438.561939   6.282464       Type_B  Area_1375   \n",
       "2  204969    44.255548   -15.662341   0.894701       Type_A   Area_272   \n",
       "3  248026  2622.821354  1373.058212  15.971260       Type_B  Area_1750   \n",
       "4   51881    52.877556    12.392606   2.876796       Type_A  Area_1773   \n",
       "\n",
       "   green_zone_part  indust_part  children_preschool  \\\n",
       "0         0.099506     0.222095         6255.829172   \n",
       "1         0.588042     0.157862         7391.899017   \n",
       "2         0.074837     0.266754         5658.091711   \n",
       "3         0.850289     0.393528        13262.734984   \n",
       "4         0.070450     0.238344         3842.416286   \n",
       "\n",
       "   preschool_education_centers_raion  ...  trc_sqm_5000_log  \\\n",
       "0                           4.076307  ...         14.688605   \n",
       "1                           7.608949  ...         15.293149   \n",
       "2                           4.054293  ...         14.162732   \n",
       "3                           6.832598  ...         14.881627   \n",
       "4                           5.030503  ...         14.302936   \n",
       "\n",
       "   sport_count_5000_log  life_full_ratio  cafe_density_5000  high_floor  \\\n",
       "0              4.046719      -178.606113          16.135148           0   \n",
       "1              3.805732         1.614971         166.763131           0   \n",
       "2              3.987516        -0.353907          12.076017           0   \n",
       "3              4.765929         0.523504         184.953625           1   \n",
       "4              4.114335         0.234364          14.630758           0   \n",
       "\n",
       "   large_apartment  rooms_inferred living_efficiency   price_doc  \\\n",
       "0                0             3.0         69.684824    6.452158   \n",
       "1                1           229.0          1.614213  101.661749   \n",
       "2                0             1.0         -0.346087    6.257546   \n",
       "3                1            91.0          0.523305   90.592523   \n",
       "4                0             1.0          0.230014    8.486698   \n",
       "\n",
       "   price_doc_log  \n",
       "0       2.008504  \n",
       "1       4.631440  \n",
       "2       1.982042  \n",
       "3       4.517350  \n",
       "4       2.249891  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a427ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE TYPE IDENTIFICATION\n",
      "============================================================\n",
      "\n",
      "Numerical features: 262\n",
      "Categorical features: 15\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 2. IDENTIFY FEATURE TYPES\n",
    "# ====================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE TYPE IDENTIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Separate features by type\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove ID and target from numerical\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['id', 'price_doc']]\n",
    "\n",
    "print(f\"\\nNumerical features: {len(numerical_cols)}\")\n",
    "print(f\"Categorical features: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22531f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MISSING VALUE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Columns with missing values: 6\n",
      "\n",
      "Top 10 features with most missing:\n",
      "office_sqm_5000_log     6.197557\n",
      "trc_sqm_5000_log        3.975604\n",
      "full_all_log            2.216443\n",
      "sport_count_5000_log    1.295267\n",
      "area_m_log              0.015426\n",
      "raion_popul_log         0.007162\n",
      "dtype: float64\n",
      "\n",
      "Features with >50% missing (will be dropped): 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 3. MISSING VALUE ANALYSIS\n",
    "# ====================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MISSING VALUE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing_train = df[numerical_cols + categorical_cols].isnull().sum()\n",
    "missing_train = missing_train[missing_train > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(missing_train) > 0:\n",
    "    missing_pct = (missing_train / len(df) * 100)\n",
    "    print(f\"\\nColumns with missing values: {len(missing_train)}\")\n",
    "    print(\"\\nTop 10 features with most missing:\")\n",
    "    print(missing_pct.head(10))\n",
    "    \n",
    "    # Identify high missing columns (>50%)\n",
    "    high_missing = missing_pct[missing_pct > 50].index.tolist()\n",
    "    print(f\"\\nFeatures with >50% missing (will be dropped): {len(high_missing)}\")\n",
    "    \n",
    "    # Drop high missing columns from both train and test\n",
    "    numerical_cols = [col for col in numerical_cols if col not in high_missing]\n",
    "    categorical_cols = [col for col in categorical_cols if col not in high_missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d1b826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MISSING VALUE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Columns with missing values: 6\n",
      "\n",
      "Top 10 features with most missing:\n",
      "office_sqm_5000_log     6.318374\n",
      "trc_sqm_5000_log        3.992852\n",
      "full_all_log            2.256103\n",
      "sport_count_5000_log    1.277816\n",
      "area_m_log              0.026996\n",
      "raion_popul_log         0.015426\n",
      "dtype: float64\n",
      "\n",
      "Features with >50% missing (will be dropped): 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 3. MISSING VALUE ANALYSIS for test data\n",
    "# ====================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MISSING VALUE ANALYSIS for test data\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing_train = test.isnull().sum()\n",
    "missing_train = missing_train[missing_train > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(missing_train) > 0:\n",
    "    missing_pct = (missing_train / len(test) * 100)\n",
    "    print(f\"\\nColumns with missing values: {len(missing_train)}\")\n",
    "    print(\"\\nTop 10 features with most missing:\")\n",
    "    print(missing_pct.head(10))\n",
    "    \n",
    "    # Identify high missing columns (>50%)\n",
    "    high_missing = missing_pct[missing_pct > 50].index.tolist()\n",
    "    print(f\"\\nFeatures with >50% missing (will be dropped): {len(high_missing)}\")\n",
    "    \n",
    "    # Drop high missing columns from both train and test\n",
    "    numerical_cols = [col for col in numerical_cols if col not in high_missing]\n",
    "    categorical_cols = [col for col in categorical_cols if col not in high_missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667214b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TARGET VARIABLE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Original target statistics:\n",
      "count    181507.000000\n",
      "mean         14.845599\n",
      "std          21.533138\n",
      "min           0.392328\n",
      "25%           5.303449\n",
      "50%           7.186257\n",
      "75%          11.781645\n",
      "max         109.864990\n",
      "Name: price_doc, dtype: float64\n",
      "Skewness: 2.79\n",
      "\n",
      "Log-transformed skewness: 1.07\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 4. TARGET ANALYSIS & TRANSFORMATION\n",
    "# ====================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TARGET VARIABLE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nOriginal target statistics:\")\n",
    "print(df['price_doc'].describe())\n",
    "print(f\"Skewness: {df['price_doc'].skew():.2f}\")\n",
    "\n",
    "# Log transform target (common for skewed price data)\n",
    "df['price_doc_log'] = np.log1p(df['price_doc'])\n",
    "print(f\"\\nLog-transformed skewness: {df['price_doc_log'].skew():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db0fcdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final numerical feature count: 262\n",
      "Final categorical feature count: 15\n",
      "\n",
      "============================================================\n",
      "BUILDING PREPROCESSING PIPELINE\n",
      "============================================================\n",
      "\n",
      "Preprocessor ready!\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 5. CLEAN FEATURE LISTS AFTER MISSING VALUE ANALYSIS\n",
    "# ====================================\n",
    "\n",
    "# Ensure id and target are removed from features\n",
    "drop_cols = ['id', 'price_doc', 'price_doc_log']\n",
    "\n",
    "numerical_cols = [col for col in numerical_cols if col not in drop_cols]\n",
    "categorical_cols = [col for col in categorical_cols if col not in drop_cols]\n",
    "\n",
    "print(\"\\nFinal numerical feature count:\", len(numerical_cols))\n",
    "print(\"Final categorical feature count:\", len(categorical_cols))\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# 6. BUILD PREPROCESSING PIPELINE\n",
    "# ====================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BUILDING PREPROCESSING PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Numerical pipeline → median imputation + scaling\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline → fill missing with 'missing' + OneHot\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# ColumnTransformer: apply proper preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "print(\"\\nPreprocessor ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8902f029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after preprocessing: 0\n"
     ]
    }
   ],
   "source": [
    "# Check missing after preprocessing\n",
    "X = df[numerical_cols + categorical_cols]\n",
    "\n",
    "Xt = preprocessor.fit_transform(X)\n",
    "\n",
    "print(\"Missing values after preprocessing:\", np.isnan(Xt).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2281836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING TRAIN-VALIDATION SPLIT\n",
      "============================================================\n",
      "\n",
      "Training set:   (127054, 277)\n",
      "Validation set: (54453, 277)\n",
      "Test set:       (77789, 277)\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 5. TRAIN–VALIDATION SPLIT\n",
    "# ====================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CREATING TRAIN-VALIDATION SPLIT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "RANDOM_STATE = 29325   # Your ERP ID\n",
    "\n",
    "# Construct final X and y\n",
    "X = df[numerical_cols + categorical_cols].copy()\n",
    "y = df['price_doc_log'].copy()\n",
    "\n",
    "# Test set features must have same columns\n",
    "test_X = test[numerical_cols + categorical_cols].copy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set:   {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set:       {test_X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f412eab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BASELINE: LINEAR REGRESSION\n",
      "============================================================\n",
      "\n",
      "Validation RMSE (log scale): 0.5262\n",
      "Validation R²: 0.6187\n",
      "Validation RMSE (original scale): 14.66\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 7. BASELINE: LINEAR REGRESSION\n",
    "# ====================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BASELINE: LINEAR REGRESSION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "baseline_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "baseline_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = baseline_pipeline.predict(X_val)\n",
    "\n",
    "# Metrics on log scale\n",
    "val_rmse_log = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"\\nValidation RMSE (log scale): {val_rmse_log:.4f}\")\n",
    "print(f\"Validation R²: {val_r2:.4f}\")\n",
    "\n",
    "# Convert back to original price scale\n",
    "y_val_orig = np.expm1(y_val)\n",
    "y_val_pred_orig = np.expm1(y_val_pred)\n",
    "\n",
    "rmse_original = np.sqrt(mean_squared_error(y_val_orig, y_val_pred_orig))\n",
    "print(f\"Validation RMSE (original scale): {rmse_original:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c0c5155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING KAGGLE SUBMISSION FILE\n",
      "============================================================\n",
      "\n",
      "Kaggle submission file saved as 'submission.csv'!\n",
      "       id  price_doc\n",
      "0  243467   7.229162\n",
      "1  230180  12.125534\n",
      "2  256036   3.071674\n",
      "3    1848   3.424784\n",
      "4   68720  11.667755\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 8. GENERATE KAGGLE SUBMISSION FILE\n",
    "# ====================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CREATING KAGGLE SUBMISSION FILE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Predict on test data (log scale)\n",
    "test_pred_log = baseline_pipeline.predict(test_X)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "test_pred = np.expm1(test_pred_log)\n",
    "\n",
    "# Build submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"price_doc\": test_pred\n",
    "})\n",
    "\n",
    "# Save CSV\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"\\nKaggle submission file saved as 'submission.csv'!\")\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8e424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
